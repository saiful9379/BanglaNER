{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bangla NER\n",
        "\n",
        "The Bangla NER model build using Spacy. This model was train for person extraction purposes.\n",
        "\n",
        "Uses Dataset are :"
      ],
      "metadata": {
        "id": "nz_O_JA_ZHcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy==3.6.1"
      ],
      "metadata": {
        "id": "kE3n869NZKeA",
        "outputId": "2d743f43-dcb7-48be-edcb-a02cac56fa76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Write the base config file to directory. For more information please check    [spacy](https://spacy.io/usage/training)"
      ],
      "metadata": {
        "id": "9uCZXOwibQ68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile base_config.cfg\n",
        "# This is an auto-generated partial config. To use it with 'spacy train'\n",
        "# you can run spacy init fill-config to auto-fill all default settings:\n",
        "# python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
        "[paths]\n",
        "train = null\n",
        "dev = null\n",
        "vectors = null\n",
        "[system]\n",
        "gpu_allocator = null\n",
        "\n",
        "[nlp]\n",
        "lang = \"en\"\n",
        "pipeline = [\"tok2vec\",\"ner\"]\n",
        "batch_size = 1000\n",
        "\n",
        "[components]\n",
        "\n",
        "[components.tok2vec]\n",
        "factory = \"tok2vec\"\n",
        "\n",
        "[components.tok2vec.model]\n",
        "@architectures = \"spacy.Tok2Vec.v2\"\n",
        "\n",
        "[components.tok2vec.model.embed]\n",
        "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
        "width = ${components.tok2vec.model.encode.width}\n",
        "attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"]\n",
        "rows = [5000, 1000, 2500, 2500]\n",
        "include_static_vectors = false\n",
        "\n",
        "[components.tok2vec.model.encode]\n",
        "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
        "width = 96\n",
        "depth = 4\n",
        "window_size = 1\n",
        "maxout_pieces = 3\n",
        "\n",
        "[components.ner]\n",
        "factory = \"ner\"\n",
        "\n",
        "[components.ner.model]\n",
        "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
        "state_type = \"ner\"\n",
        "extra_state_tokens = false\n",
        "hidden_width = 64\n",
        "maxout_pieces = 2\n",
        "use_upper = true\n",
        "nO = null\n",
        "\n",
        "[components.ner.model.tok2vec]\n",
        "@architectures = \"spacy.Tok2VecListener.v1\"\n",
        "width = ${components.tok2vec.model.encode.width}\n",
        "\n",
        "[corpora]\n",
        "\n",
        "[corpora.train]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.train}\n",
        "max_length = 0\n",
        "\n",
        "[corpora.dev]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.dev}\n",
        "max_length = 0\n",
        "\n",
        "[training]\n",
        "dev_corpus = \"corpora.dev\"\n",
        "train_corpus = \"corpora.train\"\n",
        "\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam.v1\"\n",
        "\n",
        "[training.batcher]\n",
        "@batchers = \"spacy.batch_by_words.v1\"\n",
        "discard_oversize = false\n",
        "tolerance = 0.2\n",
        "\n",
        "[training.batcher.size]\n",
        "@schedules = \"compounding.v1\"\n",
        "start = 100\n",
        "stop = 1000\n",
        "compound = 1.001\n",
        "\n",
        "[initialize]\n",
        "vectors = ${paths.vectors}"
      ],
      "metadata": {
        "id": "6f1M6TPPZkTI",
        "outputId": "1b6b6a92-59ee-4b21-922f-2199b186408a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing base_config.cfg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Base config to training config file"
      ],
      "metadata": {
        "id": "e_2Ngh8Fb07v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config ./base_config.cfg ./config.cfg"
      ],
      "metadata": {
        "id": "n7PeyRekbAEO",
        "outputId": "8dde7e45-d357-48a5-94fa-211d5eefa92c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 18:00:10.679830: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 18:00:10.679903: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 18:00:10.679943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 18:00:10.689402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 18:00:11.978788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data conversion to spacy format. Here we convert BLIOU form to spacy format.\n",
        "\n",
        "BLIOU and BIO format are similar type data format for NER.\n",
        "\n",
        "BLIOU data format:\n",
        "\n",
        "    B = Begin\n",
        "\n",
        "    L = Last\n",
        "\n",
        "    I = Inside\n",
        "\n",
        "    O = Outside\n",
        "\n",
        "    U = Unique\n",
        "\n",
        "IOB data format:\n",
        "\n",
        "    I = Inside\n",
        "\n",
        "    O = Outside\n",
        "\n",
        "    B = Begin\n"
      ],
      "metadata": {
        "id": "hlvsmt0VcJlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wget\n",
        "# import wget\n",
        "\n",
        "# # ! wget -r \"https://drive.google.com/file/d/1-szaaF__gc0n8_X2grhVWbRLRKo_Havb/view?usp=sharing\"\n",
        "\n",
        "# !wget --no-check-certificate \"https://drive.google.com/file/d/1-szaaF__gc0n8_X2grhVWbRLRKo_Havb/view?usp=sharing\" -O ner_data.zip\n"
      ],
      "metadata": {
        "id": "95rWcxRHb8z1",
        "outputId": "7d6a2e2a-d88f-411e-9fa0-e8274dae7453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "--2023-12-07 18:15:57--  https://drive.google.com/file/d/1-szaaF__gc0n8_X2grhVWbRLRKo_Havb/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.139.139, 74.125.139.113, 74.125.139.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.139.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘ner_data.zip’\n",
            "\n",
            "ner_data.zip            [ <=>                ]  82.63K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-12-07 18:15:57 (20.1 MB/s) - ‘ner_data.zip’ saved [84610]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Googe Drive dataset link directory : https://drive.google.com/file/d/1-twRMl-2XfNrrchxqMW0hWaa9mopJGrw/view?usp=sharing"
      ],
      "metadata": {
        "id": "aYW8bfu1floF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1zZCmTWekb8",
        "outputId": "86244520-ec32-4642-bdfc-0a7f3bd70879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/bangla_ner_bliou.zip ./"
      ],
      "metadata": {
        "id": "ZkdLEZhefwDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bangla_ner_bliou.zip"
      ],
      "metadata": {
        "id": "4mE2ALxQgDy7",
        "outputId": "0fbcf950-dfef-44a4-de1c-5795c61fe547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  bangla_ner_bliou.zip\n",
            "   creating: bangla_ner_bliou/\n",
            "  inflating: bangla_ner_bliou/train.json  \n",
            "  inflating: bangla_ner_bliou/val.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert bangla ber Bliou data format to spacy format"
      ],
      "metadata": {
        "id": "e4irl3hlgtcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy convert bangla_ner_bliou/train.json ./bangla_ner_bliou\n",
        "!python -m spacy convert bangla_ner_bliou/val.json ./bangla_ner_bliou"
      ],
      "metadata": {
        "id": "OQPbIKc4gIU8",
        "outputId": "00e8ef78-7a4c-4808-ad25-fecdb2fb5ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 18:21:32.031072: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 18:21:32.031160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 18:21:32.031208: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 18:21:32.044615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 18:21:33.929505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Generated output file (20831 documents):\n",
            "bangla_ner_bliou/train.spacy\u001b[0m\n",
            "2023-12-07 18:22:07.303664: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 18:22:07.303749: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 18:22:07.303797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 18:22:07.316833: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 18:22:09.148478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Generated output file (5208 documents):\n",
            "bangla_ner_bliou/val.spacy\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training The Spacy Name Entity Recognition(NER) Model"
      ],
      "metadata": {
        "id": "xpV0yDAUhFqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.sh\n",
        "python -m spacy train config.cfg \\\n",
        "    --output ./models \\\n",
        "    --paths.train ./bangla_ner_bliou/train.spacy \\\n",
        "    --paths.dev ./bangla_ner_bliou/val.spacy"
      ],
      "metadata": {
        "id": "8rXRL8GEgjtT",
        "outputId": "e9d7ecb9-5d3a-405e-9457-72bc18df8787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash train.sh"
      ],
      "metadata": {
        "id": "8AvTHwTehhwz",
        "outputId": "42857601-f515-4cba-9e9c-fa54a032166c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 18:26:25.202401: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 18:26:25.202475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 18:26:25.202521: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 18:26:25.214359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 18:26:27.048240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Created output directory: models\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: models\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     42.83    0.00    0.00    0.00    0.00\n",
            "  0     200         21.63   1253.51   14.52   38.35    8.95    0.15\n",
            "  0     400         43.56    827.08   28.06   47.92   19.83    0.28\n",
            "  0     600         49.80    864.45   36.16   53.89   27.20    0.36\n",
            "  0     800        169.24    969.16   42.35   54.62   34.57    0.42\n",
            "  0    1000         83.19   1223.52   49.75   63.14   41.05    0.50\n",
            "  0    1200        102.08   1341.78   58.48   67.14   51.79    0.58\n",
            "  0    1400        118.51   1560.74   57.62   73.50   47.38    0.58\n",
            "  1    1600        154.71   1192.27   56.91   70.61   47.66    0.57\n",
            "  1    1800        171.05   1393.46   60.26   67.84   54.20    0.60\n",
            "  2    2000        192.96   1535.09   63.18   67.26   59.57    0.63\n",
            "  2    2200        264.45   1189.62   63.04   68.76   58.20    0.63\n",
            "  3    2400        207.49   1375.58   61.44   72.76   53.17    0.61\n",
            "  4    2600        210.36   1139.17   63.41   70.45   57.64    0.63\n",
            "  4    2800        234.87    862.28   59.85   72.90   50.76    0.60\n",
            "  5    3000        218.23    915.72   61.29   72.46   53.10    0.61\n",
            "  6    3200        202.26    791.54   61.93   73.62   53.44    0.62\n",
            "  6    3400        224.58    722.12   62.03   73.26   53.79    0.62\n",
            "  7    3600        323.19    706.01   61.65   72.57   53.58    0.62\n",
            "  8    3800        231.65    726.41   61.51   72.46   53.44    0.62\n",
            "  8    4000        227.30    648.82   62.10   73.70   53.65    0.62\n",
            "  9    4200        312.94    569.33   61.10   72.21   52.96    0.61\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "models/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "L2Kx8zC3iDso"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C3qlaxL2h3kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "C1Yvu8vNiLI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser and NER\n",
        "nlp = spacy.load(\"./models/model-best\")\n",
        "\n",
        "text_list = [\n",
        "    \": আল স্কিনিয়ার গিটার, পিয়ানো, ভোকাল, মগ সিনথেসাইজার\",\n",
        "    ]\n",
        "for text in text_list:\n",
        "    doc = nlp(text)\n",
        "\n",
        "    print(f\"Input: {text}\")\n",
        "    for entity in doc.ents:\n",
        "        print(f\"Entity: {entity.text}, Label: {entity.label_}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "id": "Fea3Lv03iNC8",
        "outputId": "8bd7f49e-5fca-4c63-c53b-ad91795c4935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: : আল স্কিনিয়ার গিটার, পিয়ানো, ভোকাল, মগ সিনথেসাইজার\n",
            "Entity: আল স্কিনিয়ার, Label: PER\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dqg-cEkKmxqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}